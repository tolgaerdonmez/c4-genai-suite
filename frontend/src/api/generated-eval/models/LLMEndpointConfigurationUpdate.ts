//@ts-nocheck
/* tslint:disable */
/* eslint-disable */
/**
 * LLM Eval Service
 * Internal evaluation service for C4 GenAI Suite
 *
 * The version of the OpenAPI document: 1.0.0
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from '../runtime';
import type { Temperature } from './Temperature';
import { TemperatureFromJSON, TemperatureFromJSONTyped, TemperatureToJSON } from './Temperature';
import type { Language1 } from './Language1';
import { Language1FromJSON, Language1FromJSONTyped, Language1ToJSON } from './Language1';
import type { C4LLMEndpointConfigurationUpdate } from './C4LLMEndpointConfigurationUpdate';
import {
  C4LLMEndpointConfigurationUpdateFromJSON,
  C4LLMEndpointConfigurationUpdateFromJSONTyped,
  C4LLMEndpointConfigurationUpdateToJSON,
} from './C4LLMEndpointConfigurationUpdate';
import type { Baseurl } from './Baseurl';
import { BaseurlFromJSON, BaseurlFromJSONTyped, BaseurlToJSON } from './Baseurl';
import type { AzureOpenAILLMEndpointConfigurationUpdate } from './AzureOpenAILLMEndpointConfigurationUpdate';
import {
  AzureOpenAILLMEndpointConfigurationUpdateFromJSON,
  AzureOpenAILLMEndpointConfigurationUpdateFromJSONTyped,
  AzureOpenAILLMEndpointConfigurationUpdateToJSON,
} from './AzureOpenAILLMEndpointConfigurationUpdate';
import type { OpenAILLMEndpointConfigurationUpdate } from './OpenAILLMEndpointConfigurationUpdate';
import {
  OpenAILLMEndpointConfigurationUpdateFromJSON,
  OpenAILLMEndpointConfigurationUpdateFromJSONTyped,
  OpenAILLMEndpointConfigurationUpdateToJSON,
} from './OpenAILLMEndpointConfigurationUpdate';

/**
 *
 * @export
 * @interface LLMEndpointConfigurationUpdate
 */
export interface LLMEndpointConfigurationUpdate {
  /**
   *
   * @type {string}
   * @memberof LLMEndpointConfigurationUpdate
   */
  type: string;
  /**
   *
   * @type {number}
   * @memberof LLMEndpointConfigurationUpdate
   */
  parallelQueries?: number;
  /**
   *
   * @type {number}
   * @memberof LLMEndpointConfigurationUpdate
   */
  maxRetries?: number;
  /**
   *
   * @type {string}
   * @memberof LLMEndpointConfigurationUpdate
   */
  endpoint?: string;
  /**
   *
   * @type {string}
   * @memberof LLMEndpointConfigurationUpdate
   */
  apiKey?: string;
  /**
   *
   * @type {number}
   * @memberof LLMEndpointConfigurationUpdate
   */
  configurationId?: number;
  /**
   *
   * @type {number}
   * @memberof LLMEndpointConfigurationUpdate
   */
  requestTimeout?: number;
  /**
   *
   * @type {string}
   * @memberof LLMEndpointConfigurationUpdate
   */
  apiVersion?: string;
  /**
   *
   * @type {string}
   * @memberof LLMEndpointConfigurationUpdate
   */
  deployment?: string;
  /**
   *
   * @type {Language1}
   * @memberof LLMEndpointConfigurationUpdate
   */
  language?: Language1 | null;
  /**
   *
   * @type {Baseurl}
   * @memberof LLMEndpointConfigurationUpdate
   */
  baseUrl?: Baseurl | null;
  /**
   *
   * @type {string}
   * @memberof LLMEndpointConfigurationUpdate
   */
  model?: string;
  /**
   *
   * @type {Temperature}
   * @memberof LLMEndpointConfigurationUpdate
   */
  temperature?: Temperature | null;
}

/**
 * Check if a given object implements the LLMEndpointConfigurationUpdate interface.
 */
export function instanceOfLLMEndpointConfigurationUpdate(value: object): value is LLMEndpointConfigurationUpdate {
  if (!('type' in value) || value['type'] === undefined) return false;
  return true;
}

export function LLMEndpointConfigurationUpdateFromJSON(json: any): LLMEndpointConfigurationUpdate {
  return LLMEndpointConfigurationUpdateFromJSONTyped(json, false);
}

export function LLMEndpointConfigurationUpdateFromJSONTyped(
  json: any,
  ignoreDiscriminator: boolean,
): LLMEndpointConfigurationUpdate {
  if (json == null) {
    return json;
  }
  return {
    type: json['type'],
    parallelQueries: json['parallelQueries'] == null ? undefined : json['parallelQueries'],
    maxRetries: json['maxRetries'] == null ? undefined : json['maxRetries'],
    endpoint: json['endpoint'] == null ? undefined : json['endpoint'],
    apiKey: json['apiKey'] == null ? undefined : json['apiKey'],
    configurationId: json['configurationId'] == null ? undefined : json['configurationId'],
    requestTimeout: json['requestTimeout'] == null ? undefined : json['requestTimeout'],
    apiVersion: json['apiVersion'] == null ? undefined : json['apiVersion'],
    deployment: json['deployment'] == null ? undefined : json['deployment'],
    language: json['language'] == null ? undefined : Language1FromJSON(json['language']),
    baseUrl: json['baseUrl'] == null ? undefined : BaseurlFromJSON(json['baseUrl']),
    model: json['model'] == null ? undefined : json['model'],
    temperature: json['temperature'] == null ? undefined : TemperatureFromJSON(json['temperature']),
  };
}

export function LLMEndpointConfigurationUpdateToJSON(value?: LLMEndpointConfigurationUpdate | null): any {
  if (value == null) {
    return value;
  }
  return {
    type: value['type'],
    parallelQueries: value['parallelQueries'],
    maxRetries: value['maxRetries'],
    endpoint: value['endpoint'],
    apiKey: value['apiKey'],
    configurationId: value['configurationId'],
    requestTimeout: value['requestTimeout'],
    apiVersion: value['apiVersion'],
    deployment: value['deployment'],
    language: Language1ToJSON(value['language']),
    baseUrl: BaseurlToJSON(value['baseUrl']),
    model: value['model'],
    temperature: TemperatureToJSON(value['temperature']),
  };
}
